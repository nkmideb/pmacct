CONFIG-KEYS for pmgrpcd.py
=================================================================
KEY:        topic
DESC:       The Kafka topic name to produce to. It is a good idea to
	    have a concept as topic, for example the following:
            [project].[env].[role]-[type]-[traffic]
            project: myproject
            env: dev, test, prod
            role: infra, flow, control, device, event
            type: metric, schema
            traffic: raw, proc
 
 
            infra producer is, e.g., pmacctd
            flow producer is, e.g., nfacctd
            control producer is, e.g., pmbmpd 
            device producer is, e.g., pmgrpcd.py
            event producer is, e.g., nfacctd (ipfix-NEL)
DEFAULT:    none
EXAMPLE:    myproject.prod.device-metric-raw
-----------------------------------------------------------------
KEY:        bsservers
DESC:       One or multiple Kafka bootstrap servers
DEFAULT:    none
EXAMPLE:    kafka.single.boot.strap.server.net:9093 or "kafka.boot.strap.server.one.net:9093, kafka.boot.strap.server.two.net:9093, kafka.boot.strap.server.three.net:9093"
-----------------------------------------------------------------
KEY:        urlscreg
DESC:       The URL to the Schema Registry server where Avro schemas are
	    registered. The server stores a 1:1 mapping among Avro
	    schemas and Avro schema IDs. A client would supply a schema
	    and be returned its ID; such ID is then used to serialize JSON
	    metrics into Avro format.
DEFAULT:    none
EXAMPLE:    https://schema-registry.some.thing.net:443
-----------------------------------------------------------------
KEY:        calocation
DESC:       The ca_location used to connect to Schema Registry
DEFAULT:    none
EXAMPLE:    /path/to/schema/registry/ssl/something_root_ca.crt
-----------------------------------------------------------------
KEY:        secproto
DESC:       security protocol
DEFAULT:    none
EXAMPLE:    ssl
-----------------------------------------------------------------
KEY:        sslcertloc
DESC:       Path/file to a SSL certification location
DEFAULT:    none
EXAMPLE:    /path/to/ssl/certificate/location/something.crt
-----------------------------------------------------------------
KEY:        sslkeyloc
DESC:       Path/file to a SSL key location
DEFAULT:    none
EXAMPLE:    /path/to/ssl/key/location/something.key
-----------------------------------------------------------------
KEY:        gpbmapfile
DESC:       This file is a way to keep the Python script as generic as
	    possible. In this file further Python classes can be added
	    in order to support more YANG models. pmgrpcd.py will read
	    this file so to be able to unmarshall JSON metrics based
	    on these Python libraries.
DEFAULT:    /etc/pmacct/telemetry/gpbmapfile.map
EXAMPLE:
            huawei-ifm            =  huawei_ifm_pb2.Ifm()
            huawei-devm           =  huawei_devm_pb2.Devm()
            openconfig-interfaces =  openconfig_interfaces_pb2.Interfaces()
-----------------------------------------------------------------
KEY:        avscmapfile
DESC:       This file is a JSON object. Based on this file, pmgrpcd.py is
	    able to get the Avro schema to serialize the JSON metrics to
	    Avro. 
            pmgrpcd.py is getting JSON-encoded metrics from routers.
	    The gRPC source IP address and YANG Encoding Path can also 
            be found in the data. IP address being e.g. "10.215.133.15" and 
            Encoding Path being e.g. "openconfig-interfaces:interfaces".
            Based on this mapping file it is possible to get the Avro
	    Schema ID (ie. 249). With such ID it is possible to get the
	    Avro schema from the Schema Registry server to serialize the
	    JSON metrics to Avro.
DEFAULT:    /etc/pmacct/telemetry/schema_id_map_file.json
EXAMPLE:    
            {
              "10.215.133.15": {
                "openconfig-interfaces:interfaces": 249
                "openconfig-platform:components": 365
              },
              "10.215.133.17": {
                "openconfig-interfaces:interfaces": 299
              }
            }
-----------------------------------------------------------------
KEY:        mitigation
DESC:       The idea of this Python script is to have something like a
	    plugin to mitigate JSON data problems. Streaming Telemetry
	    today (1Q 2019) is not very well standardized. There are
	    several pieces that vendors do in different ways. Also there
	    are bugs (e.g.. missing values) and not correct implementations
	    of the already existing standards. There are many optional
	    parameters (e.g. some leafs) but also optional structures
	    (i.e. records). For example: if there are multiple interfaces
	    within the JSON message there has to be a record "interfaces"
	    as parent of "interface"; whereas with only one interface
	    within the message the record "interfaces" is optional. For
	    Big Data (IT and data analytics) this is very hard to handle.
	    The pmgrpcd.py (not the mitigation.py!) flattens data by
	    splitting objects within the same message to multiple flat
	    messages. It is possible with the mitigation script to
	    mitigate JSON data before they are serialized. ie. all
	    metrics must have a fixed data structure, like a parent
	    "interfaces" array containing a single "interface" object.
DEFAULT:    /etc/pmacct/telemetry/mitigation.py
EXAMPLE:    see default file: /etc/pmacct/telemetry/mitigation.py
-----------------------------------------------------------------
KEY:        debug
DESC:       Enable debug
DEFAULT:    False
EXAMPLE:    False
-----------------------------------------------------------------
KEY:        pmgrpcdlogfile
DESC:       This logfile is for collection events of pmgrpcd.py
DEFAULT:    /var/log/pmgrpcd.log
EXAMPLE:    /var/log/pmgrpcd.log
-----------------------------------------------------------------
KEY:        serializelogfile
DESC:       This logfile if for data serialization events of pmgrpcd.py
DEFAULT:    /var/log/pmgrpcd_avro.log
EXAMPLE:    /var/log/pmgrpcd_avro.log
-----------------------------------------------------------------
KEY:        ipport
DESC:       IP address and port the daemon pmgrpcd.py listens on. By
	    default the daemon listens on all interfaces on port 10000.
DEFAULT:    [::]:10000
EXAMPLE:    [::]:10000
-----------------------------------------------------------------
KEY:        workers
DESC:       Number of worker threads to process input data.
DEFAULT:    20
EXAMPLE:    20
-----------------------------------------------------------------
KEY:        processpool
DESC:       Number of processes within the ProcessPool of Kafka Avro
	    exporter.
DEFAULT:    8
EXAMPLE:    8
-----------------------------------------------------------------
KEY:        cisco
DESC:       Enable/disable processing of metrics produced by Cisco devices
DEFAULT:    True
EXAMPLE:    True
-----------------------------------------------------------------
KEY:        huawei
DESC:       Enable/disable processing of metrics produced by Huawei devices
DEFAULT:    True
EXAMPLE:    True
-----------------------------------------------------------------
KEY:        cenctype
DESC:       cenctype is the type of encoding for cisco.
            This is because some protofiles are incompatible.
            With cenctype=gpbkv only cisco is enabled.
            The encoding type can be json, gpbcomp, gpbkv
DEFAULT:    json
EXAMPLE:    json, gpbcomp, gpbkv
-----------------------------------------------------------------
KEY:        example
DESC:       Enable/disable flag to produce example files for different
	    network elements. If this flag is enabled example path files
	    for each network element (NE) for each YANG model are going
	    to be generated. In this file there will be an example (the
	    first message of each NE/YANG model) where to look for what
	    is being serialized to Avro for production to Kafka.
DEFAULT:    True
EXAMPLE:    True
-----------------------------------------------------------------
KEY:        examplepath
DESC:       The directory where example files will be produced to.
DEFAULT:    /tmp/stexamples
EXAMPLE:    /tmp/stexamples
-----------------------------------------------------------------
KEY:        jsondatafile
DESC:       This ioption is to serialize manually with avscid and
            jsondatafile (for development)
DEFAULT:    /tmp/stexamples/jsondatafile.json
EXAMPLE:    /tmp/stexamples/jsondatafile.json
-----------------------------------------------------------------
KEY:        rawdatafile
DESC:       This option is to process manually (via mitigation) process a
            rawdatafile with a single rawrecord (for development)
DEFAULT:    /tmp/stexamples/rawdatafile.json
EXAMPLE:    /tmp/stexamples/rawdatafile.json
-----------------------------------------------------------------
KEY:        jsondatadumpfile
DESC:       If enabled, mitigated metrics will be dumped to this file.
	    With this file it is possible to find Avro schema mismatching
	    problems.
DEFAULT:    /tmp/stexamples/jsondatadumpfile.json
EXAMPLE:    /tmp/stexamples/jsondatadumpfile.json
-----------------------------------------------------------------
KEY:        rawdatadumpfile
DESC:       If enabled, raw data collected by pmgrpcd.py will be dumped
	    to this file. With this file it is possible to troubleshoot
	    issues related to data structures.
DEFAULT:    /tmp/stexamples/rawdatadumpfile.json
EXAMPLE:    /tmp/stexamples/rawdatadumpfile.json
-----------------------------------------------------------------
KEY:        zmq
DESC:       Enable ZMQ forwarding. Output encoding is JSON.
DEFAULT:    False
EXAMPLE:    False
-----------------------------------------------------------------
KEY:        zmqipport
DESC:       Specify IP address and port for ZMQ forwarding.
DEFAULT:    tcp://127.0.0.1:50000
EXAMPLE:    tcp://127.0.0.1:50000
-----------------------------------------------------------------
KEY:        kafkaavro
DESC:       Enable/disable forwarding to Kafka and serializing to Avro.
DEFAULT:    True
EXAMPLE:    True
-----------------------------------------------------------------
KEY:        kafkasimple
DESC:       Enable/disable forwarding to Kafka and serializing to JSON.
	    Also, optionally flatten output objects, see 'flatten'.
DEFAULT:    False
EXAMPLE:    False
-----------------------------------------------------------------
KEY:        flatten
DESC:       Enable/disable flattening of complex (ie. nested) input
	    objects into multiple simpler ones suitable to be ingested
	    in a Big Data system.
DEFAULT:    True
EXAMPLE:    True
-----------------------------------------------------------------
KEY:        onlyopenconfig
DESC:       Enable/disable vendor-specific YANG models leaving only the
	    vendor independent ones, ie. openconfig or IETF ones.
DEFAULT:    False
EXAMPLE:    False
-----------------------------------------------------------------
